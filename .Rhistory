library("knitr")
opts_chunk$set(cache=TRUE,eval=TRUE)
data<-read.csv("pml-training.csv",na.strings=c("NA",""))
newdata<-data[,colSums(!is.na(data)) == nrow(data)]
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
#split the data set into training set and cross validation set
library(caret)
inTrain <- createDataPartition(y=newdata$classe,p=0.7, list=FALSE)
training <- newdata[inTrain,]   #13737 obs.
validation <- newdata[-inTrain,]    #5885 obs.
Tree_Fit <- train(classe ~.,data = training,method="rpart")
confusionMatrix(validation$classe, predict(Tree_Fit, validation))
RF_Fit <- train(classe~.,data =training,method='rf')
install.packages("randomForest")
install.packages("randomForest")
install.packages("randomForest")
RF_Fit <- train(classe~.,data =training,method='rf')
Finally, the random forests model was used to predict 20 different test cases in the testing set.
library("knitr")
opts_chunk$set(cache=TRUE,eval=TRUE)
data<-read.csv("pml-training.csv",na.strings=c("NA",""))
newdata<-data[,colSums(!is.na(data)) == nrow(data)]
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
library(caret)
inTrain <- createDataPartition(y=newdata$classe,p=0.7, list=FALSE)
training <- newdata[inTrain,]   #13737 obs.
validation <- newdata[-inTrain,]    #5885 obs.
Tree_Fit <- train(classe ~.,data = training,method="rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
library("knitr")
opts_chunk$set(cache=TRUE,eval=TRUE)
trainDf <- read.csv("pml-training.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
testDf <- read.csv("pml-testing.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
names(trainDf)[1:7]
removeVars <- grepl("^X|user|timestamp|window", names(trainDf))
trainDf <- trainDf[, !removeVars]
testDf <- testDf[, !removeVars]
suppressPackageStartupMessages(require(caret))
nzv <- nearZeroVar(trainDf, saveMetrics=TRUE)
nzv <- nearZeroVar(trainDf)
filteredTrainDf <- trainDf[, -nzv]
filteredTestDf <- testDf[, -nzv]
Train <- filteredTrainDf[, colSums(is.na(filteredTrainDf)) <= 0.8*nrow(filteredTrainDf)]
Test <- filteredTestDf[, colSums(is.na(filteredTestDf)) <= 0.8*nrow(filteredTestDf)]
set.seed(22561)
inTrain <- createDataPartition(Train$classe, p=0.70, list=F)
training <- Train[inTrain,]
testing <- Train[-inTrain,]
corMatrix <- cor(training[, -53]) # Column 53 = Outcome
controlCV <- trainControl(method="cv")
rf.Model <- train(classe ~., data=training, method="rf", trControl=controlCV)
library(ggplot2)
rf.Model <- train(classe ~., data=training, method="rf", trControl=controlCV)
library("ggplot2")
library("randomForest")
library("knitr")
opts_chunk$set(cache=TRUE,eval=TRUE)
trainDf <- read.csv("pml-training.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
testDf <- read.csv("pml-testing.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
names(trainDf)[1:7]
removeVars <- grepl("^X|user|timestamp|window", names(trainDf))
trainDf <- trainDf[, !removeVars]
testDf <- testDf[, !removeVars]
suppressPackageStartupMessages(require(caret))
nzv <- nearZeroVar(trainDf, saveMetrics=TRUE)
nzv <- nearZeroVar(trainDf)
filteredTrainDf <- trainDf[, -nzv]
filteredTestDf <- testDf[, -nzv]
Train <- filteredTrainDf[, colSums(is.na(filteredTrainDf)) <= 0.8*nrow(filteredTrainDf)]
Test <- filteredTestDf[, colSums(is.na(filteredTestDf)) <= 0.8*nrow(filteredTestDf)]
set.seed(22561)
inTrain <- createDataPartition(Train$classe, p=0.70, list=F)
training <- Train[inTrain,]
testing <- Train[-inTrain,]
corMatrix <- cor(training[, -53]) # Column 53 = Outcome
controlCV <- trainControl(method="cv")
rf.Model <- train(classe ~., data=training, method="rf", trControl=controlCV)
library(ggplot2)
library(randomForest)
library(knitr)
library(caret)
library(Hmisc)
library(foreach)
library(doParallel)
options(warn=1)
install.packages("Hmisc")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
library(foreach)
install.packages("doParallel")
library(ggplot2)
library(randomForest)
library(knitr)
library(caret)
library(Hmisc)
library(foreach)
library(doParallel)
options(warn=1)
options(stringsAsFactors = FALSE)
opts_chunk$set(cache=TRUE,eval=TRUE)
training <- read.csv("pml-training.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
names(training)[1:7]
removeVars <- grepl("^X|user|timestamp|window", names(training))
training <- training[, !removeVars]
testing <- testing[, !removeVars]
suppressPackageStartupMessages(require(caret))
nzv <- nearZeroVar(training, saveMetrics=TRUE)
nzv <- nearZeroVar(training)
filteredtraining <- training[, -nzv]
filteredtesting <- testing[, -nzv]
Train <- filteredtraining[, colSums(is.na(filteredtraining)) <= 0.8*nrow(filteredtraining)]
Test <- filteredtesting[, colSums(is.na(filteredtesting)) <= 0.8*nrow(filteredtesting)]
names(trainin)
names(training)
set.seed(12345)
training <- training[,union(grep("^accel_", colnames(training)),grep("classe",colnames(training)) )]
testing <- testing[,union(grep("^accel_", colnames(testing)),grep("classe",colnames(testing)) )]
names(training)
suppressPackageStartupMessages(require(caret))
nzv <- nearZeroVar(training, saveMetrics=TRUE)
nzv <- nearZeroVar(training)
filteredtraining <- training[, -nzv]
filteredtesting <- testing[, -nzv]
Train <- filteredtraining[, colSums(is.na(filteredtraining)) <= 0.8*nrow(filteredtraining)]
Test <- filteredtesting[, colSums(is.na(filteredtesting)) <= 0.8*nrow(filteredtesting)]
inTrain <- createDataPartition(Train$classe, p=0.70, list=F)
Tree_Fit <- train(classe ~.,data = training,method="rpart")
confusionMatrix(validation$classe, predict(Tree_Fit, validation))
RF_Fit <- train(classe~.,data =training,method='rf')
confusionMatrix(validation$classe, predict(RF_Fit, validation))
partition <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
sample1 <- training[partition, ]
psample1 <-  training[-partition, ]
sample1$classe <-as.factor(sample1$classe)
sample1[, 1:6] <- sapply(sample1[, 1:6], as.numeric)
psample1$classe <-as.factor(psample1$classe)
psample1[, 1:6] <- sapply(psample1[, 1:6], as.numeric)
Tree_Fit <- train(classe ~.,data = sample1,method="rpart")
confusionMatrix(psample1$classe, predict(Tree_Fit, psample1))
RF_Fit <- train(classe~.,data =sample1,method='rf')
registerDoParallel()
rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x=sample1[,1:12], y=sample1$classe, ntree=ntree)
}
confusionMatrix(psample1$classe, predict(RF_Fit, psample1))
registerDoParallel()
RF_Fit <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x=sample1[,1:12], y=sample1$classe, ntree=ntree)
}
confusionMatrix(psample1$classe, predict(RF_Fit, psample1))
testing<-read.csv("pml-testing.csv",na.strings=c("NA",""))
#preprocess the testing set
testProc<-subset(testing,select=names(newdata[,-53]))
#predict the class
answers<-predict(RF_Fit, testProc)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
newdata<-training[,colSums(!is.na(data)) == nrow(data)]
newdata<-training[,colSums(!is.na(training)) == nrow(training)]
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
training <- read.csv("pml-training.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","NaN","#DIV/0!", ""))
newdata<-training[,colSums(!is.na(training)) == nrow(training)]
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
partition <- createDataPartition(y = newdata$classe, p = 0.7, list = FALSE)
sample1 <- training[partition, ]
psample1 <-  training[-partition, ]
sample1$classe <-as.factor(sample1$classe)
sample1[, 1:6] <- sapply(sample1[, 1:6], as.numeric)
psample1$classe <-as.factor(psample1$classe)
psample1[, 1:6] <- sapply(psample1[, 1:6], as.numeric)
Tree_Fit <- train(classe ~.,data = sample1,method="rpart")
sample1 <- training[partition, ]
psample1 <-  training[-partition, ]
Tree_Fit <- train(classe ~.,data = sample1,method="rpart")
partition <- createDataPartition(y = newdata$classe, p = 0.7, list = FALSE)
sample1 <- training[partition, ]
psample1 <-  training[-partition, ]
Tree_Fit <- train(classe ~.,data = sample1,method="rpart")
opts_chunk$set(cache=TRUE,eval=TRUE)
data<-read.csv("pml-training.csv",na.strings=c("NA",""))
newdata<-data[,colSums(!is.na(data)) == nrow(data)]
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
library(caret)
inTrain <- createDataPartition(y=newdata$classe,p=0.7, list=FALSE)
training <- newdata[inTrain,]   #13737 obs.
validation <- newdata[-inTrain,]    #5885 obs.
Tree_Fit <- train(classe ~.,data = training,method="rpart")
opts_chunk$set(cache=TRUE,eval=TRUE)
